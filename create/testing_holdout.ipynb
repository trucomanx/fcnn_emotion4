{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e77e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_default_json_conf_file='cnn_emotion4_testing_holdout_default.json';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3410f40c-893b-449d-b024-7781e0d76733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ce46fc-8392-4e0b-a820-3ce426fcc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../library');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c365c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbfad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load json conf file\n",
    "fd = open(os.path.join('./',input_default_json_conf_file));\n",
    "DATA = json.load(fd);\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0f452-3278-49c0-9601-c8a443dbc32b",
   "metadata": {},
   "source": [
    "# Variable globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83c3fa6-dbbb-4644-a12f-e497f971a446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dataset_base_dir: /media/fernando/INFORMATION/TMP/DATABASE/RAW/DATASET1-FACE\n",
      "dataset_labels_file: test.csv\n",
      "       dataset_name: DATASET1-FACE\n",
      "         model_type: efficientnet_b3\n",
      "         model_file: /media/fernando/INFORMATION/DOCTORADO2/cnn_emotion4/cross-validation/DATASET1-FACE/skfold5_efficientnet_b3/model_1.h5\n",
      "              times: 10\n",
      "         BATCH_SIZE: 32\n",
      "    output_base_dir: /mnt/boveda/DOCTORADO2/cnn_emotion4/test_holdout\n"
     ]
    }
   ],
   "source": [
    "## Seed for the random variables\n",
    "seed_number=0;\n",
    "\n",
    "## Dataset \n",
    "dataset_base_dir     = DATA['dataset_base_dir'];\n",
    "dataset_labels_file  = DATA['dataset_labels_file'];\n",
    "dataset_name         = DATA['dataset_name'];\n",
    "\n",
    "## Training hyperparameters\n",
    "BATCH_SIZE = DATA['batch_size'];\n",
    "\n",
    "## Model of network\n",
    "## 'mobilenet_v3', 'efficientnet_b3', 'inception_v3', 'inception_resnet_v2', 'resnet_v2_50'\n",
    "model_type = DATA['model_type'];\n",
    "\n",
    "## Model filepath\n",
    "model_dir = DATA['model_dir'];\n",
    "\n",
    "## times to count time\n",
    "times = DATA['times'];\n",
    "\n",
    "## Output\n",
    "output_base_dir = DATA['output_base_dir'];\n",
    "\n",
    "##############################################\n",
    "\n",
    "best_model_file = os.path.join(model_dir,'model_'+model_type+'.h5');\n",
    "\n",
    "\n",
    "'''\n",
    "print('   dataset_base_dir:',dataset_base_dir)\n",
    "print('dataset_labels_file:',dataset_labels_file)\n",
    "print('       dataset_name:',dataset_name)\n",
    "print('         model_type:',model_type)\n",
    "print('          model_dir:',model_dir)\n",
    "print('              times:',times)\n",
    "print('         BATCH_SIZE:',BATCH_SIZE)\n",
    "print('    output_base_dir:',output_base_dir)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc12f1-6c56-4e35-b126-8979486b695b",
   "metadata": {},
   "source": [
    "# If command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2087e4ea-a8e4-4ed5-b2f7-2b391f054575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dataset_base_dir: /media/fernando/INFORMATION/TMP/DATABASE/RAW/DATASET1-FACE\n",
      "dataset_labels_file: test.csv\n",
      "       dataset_name: DATASET1-FACE\n",
      "         model_type: efficientnet_b3\n",
      "         model_file: /media/fernando/INFORMATION/DOCTORADO2/cnn_emotion4/cross-validation/DATASET1-FACE/skfold5_efficientnet_b3/model_1.h5\n",
      "              times: 10\n",
      "         BATCH_SIZE: 32\n",
      "    output_base_dir: /mnt/boveda/DOCTORADO2/cnn_emotion4/test_holdout\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(sys.argv)):\n",
    "    if   sys.argv[n]=='--dataset-dir':\n",
    "        dataset_base_dir=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--dataset-file':\n",
    "        dataset_labels_file=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--dataset-name':\n",
    "        dataset_name=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--model':\n",
    "        model_type=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--model-dir':\n",
    "        model_dir=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--times':\n",
    "        times=int(sys.argv[n+1]);\n",
    "    elif sys.argv[n]=='--batch-size':\n",
    "        BATCH_SIZE=int(sys.argv[n+1]);\n",
    "    elif sys.argv[n]=='--output-dir':\n",
    "        output_base_dir=sys.argv[n+1];\n",
    "\n",
    "best_model_file = os.path.join(model_dir,'model_'+model_type+'.h5');\n",
    "\n",
    "print('   dataset_base_dir:',dataset_base_dir)\n",
    "print('dataset_labels_file:',dataset_labels_file)\n",
    "print('       dataset_name:',dataset_name)\n",
    "print('         model_type:',model_type)\n",
    "print('          model_dir:',model_dir)\n",
    "print('              times:',times)\n",
    "print('         BATCH_SIZE:',BATCH_SIZE)\n",
    "print('    output_base_dir:',output_base_dir)\n",
    "\n",
    "print('         model_file:',best_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1dee5-778a-4fd9-80de-90620bb33128",
   "metadata": {},
   "source": [
    "# Set seed of random variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ddef12f-6604-4c71-9473-15f328e954dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "tf.keras.utils.set_random_seed(seed_number);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5242bb-2077-4de0-8f41-374768f159e9",
   "metadata": {},
   "source": [
    "# Loading data of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f79564c-1ed0-4459-90cc-84e2bdda978c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 filename     label\n",
      "0      neutral/frame_count100_cam1_p0.png   neutral\n",
      "1      negative/frame_count54_cam2_p0.png  negative\n",
      "2         pain/frame_count317_cam2_p0.png      pain\n",
      "3      neutral/frame_count359_cam1_p0.png   neutral\n",
      "4       neutral/frame_count80_cam2_p0.png   neutral\n",
      "...                                   ...       ...\n",
      "1740   neutral/frame_count314_cam1_p0.png   neutral\n",
      "1741  positive/frame_count378_cam1_p0.png  positive\n",
      "1742       pain/frame_count56_cam2_p0.png      pain\n",
      "1743  negative/frame_count347_cam1_p0.png  negative\n",
      "1744       pain/frame_count53_cam0_p0.png      pain\n",
      "\n",
      "[1745 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load filenames and labels\n",
    "test_data = pd.read_csv(os.path.join(dataset_base_dir,dataset_labels_file));\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67beeb38-1ad1-455d-8a71-5900a1e88163",
   "metadata": {},
   "source": [
    "# Data augmentation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e3e68f-50e7-4f8c-9cd6-ae3261e8f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "idg_test= ImageDataGenerator(rescale=1./255 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5189cf-b447-4b0a-b9f3-56f304d6fdde",
   "metadata": {},
   "source": [
    "# Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a786de7-43ac-4597-92eb-d9eee66f81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir = os.path.join(output_base_dir,dataset_name,'test_holdout',model_type);\n",
    "\n",
    "os.makedirs(output_dir,exist_ok = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf04e51-7a7b-4116-8e1e-04e5f358c5dc",
   "metadata": {},
   "source": [
    "# Create new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d629ba9-d621-4905-a88f-a0730d6c1802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded layer with efficientnet_b3\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1536)              10783528  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 6148      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,789,676\n",
      "Trainable params: 6,148\n",
      "Non-trainable params: 10,783,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import BodyEmotion4Lib.lib_model as mpp\n",
    "\n",
    "model, target_size = mpp.create_model(model_type=model_type,load_weights=False,file_of_weight=best_model_file);\n",
    "model.summary()\n",
    "\n",
    "mpp.save_model_parameters(model, os.path.join(output_dir,'parameters_stats.m'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59917a-4069-439f-9108-e5b139498b01",
   "metadata": {},
   "source": [
    "# Defining directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac8f2152-96da-447d-b437-84f11e12937f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1745 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data_generator  = idg_test.flow_from_dataframe(test_data, \n",
    "                                                    directory = dataset_base_dir,\n",
    "                                                    target_size=target_size,\n",
    "                                                    x_col = \"filename\", \n",
    "                                                    y_col = \"label\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    shuffle=True\n",
    "                                                    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1be572-b9c7-422c-9518-53735f9425c7",
   "metadata": {},
   "source": [
    "# Compile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13cd68b8-e1aa-4ef4-af04-e05781f309ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE NEW MODEL\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083be078-c76e-423a-a538-6e5c6c9cda8c",
   "metadata": {},
   "source": [
    "# Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33e25913-47a1-4e14-b560-2c5037904a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytictoc import TicToc\n",
    "t = TicToc() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97efa97-b910-43a5-97ee-a18a230305e7",
   "metadata": {},
   "source": [
    "# Evaluate best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d4f6536-46f0-4c89-b98f-7cb5a4075cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: 1745\n",
      "{'loss': 0.24139080941677094, 'accuracy': 0.921489953994751} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L=test_data_generator.samples;\n",
    "print('L:',L);\n",
    "\n",
    "t.tic();\n",
    "for m in range(times):\n",
    "    results = model.evaluate(test_data_generator,verbose=0)\n",
    "t0=t.tocvalue();\n",
    "\n",
    "results = dict(zip(model.metrics_names,results))\n",
    "results['block_delayms']=t0*1000.0/(times*L);\n",
    "print(results,\"\\n\\n\");\n",
    "\n",
    "\n",
    "with open(os.path.join(output_dir,\"results_testing.m\"), 'w') as f: \n",
    "    for key, value in results.items(): \n",
    "        f.write('%s=%s;\\n' % (key, value));\n",
    "\n",
    "\n",
    "# final all json\n",
    "with open(os.path.join(output_dir,\"testing_data_results.json\"), 'w') as f:\n",
    "    json.dump(results, f,indent=4);\n",
    "\n",
    "tf.keras.backend.clear_session()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
