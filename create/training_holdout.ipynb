{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d874f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c38da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_default_json_conf_file='cnn_emotion4_training_default.json';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3410f40c-893b-449d-b024-7781e0d76733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4ce46fc-8392-4e0b-a820-3ce426fcc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../library');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d770d436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00acb00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load json conf json file\n",
    "fd = open(os.path.join('./',input_default_json_conf_file));\n",
    "DATA = json.load(fd);\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0f452-3278-49c0-9601-c8a443dbc32b",
   "metadata": {},
   "source": [
    "# Variable globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83c3fa6-dbbb-4644-a12f-e497f971a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seed for the random variables\n",
    "seed_number=0;\n",
    "\n",
    "## Dataset \n",
    "dataset_base_dir    = DATA['dataset_train_base_dir'];\n",
    "dataset_labels_file = DATA['dataset_train_labels_file'];\n",
    "\n",
    "dataset_base_test_dir    = DATA['dataset_test_base_dir'];\n",
    "dataset_labels_test_file = DATA['dataset_test_labels_file'];\n",
    "\n",
    "dataset_name        = DATA['dataset_name'];\n",
    "\n",
    "## Training hyperparameters\n",
    "EPOCAS     = DATA[\"epochs\"];\n",
    "BATCH_SIZE = DATA[\"batch_size\"];\n",
    "\n",
    "## Model of network\n",
    "## 'mobilenet_v3', 'efficientnet_b3', 'inception_v3', 'inception_resnet_v2', 'resnet_v2_50'\n",
    "model_type = DATA[\"model_type\"];\n",
    "\n",
    "## Output\n",
    "output_base_dir = DATA[\"output_base_dir\"];\n",
    "\n",
    "## fine tuning\n",
    "fine_tuning=DATA[\"fine_tuning\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65186ce7",
   "metadata": {},
   "source": [
    "# Parametros de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a1d31d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dataset_base_dir: /media/fernando/Expansion/DATASET/TESE/PATIENT-RECOGNITION/PATIENT-IMAGES/perwi/dataset/train/\n",
      "     dataset_labels_file: labels-emotion4-v1.csv\n",
      "   dataset_base_test_dir: /media/fernando/Expansion/DATASET/TESE/PATIENT-RECOGNITION/PATIENT-IMAGES/perwi/dataset/test/\n",
      "dataset_labels_test_file: labels-emotion4-v1.csv\n",
      "            dataset_name: perwi\n",
      "              model_type: mobilenet_v3\n",
      "                  EPOCAS: 50\n",
      "              BATCH_SIZE: 32\n",
      "         output_base_dir: /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(sys.argv)):\n",
    "    if sys.argv[n]=='--dataset-train-dir':\n",
    "        dataset_base_dir=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--dataset-train-file':\n",
    "        dataset_labels_file=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--dataset-test-dir':\n",
    "        dataset_base_test_dir=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--dataset-test-file':\n",
    "        dataset_labels_test_file=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--dataset-name':\n",
    "        dataset_name=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--model':\n",
    "        model_type=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--epochs':\n",
    "        EPOCAS=int(sys.argv[n+1]);\n",
    "    elif sys.argv[n]=='--batch-size':\n",
    "        BATCH_SIZE=int(sys.argv[n+1]);\n",
    "    elif sys.argv[n]=='--fine-tuning':\n",
    "        fine_tuning=sys.argv[n+1].lower()=='true';\n",
    "    elif sys.argv[n]=='--output-dir':\n",
    "        output_base_dir=sys.argv[n+1];\n",
    "        \n",
    "print('        dataset_base_dir:',dataset_base_dir)\n",
    "print('     dataset_labels_file:',dataset_labels_file)\n",
    "print('   dataset_base_test_dir:',dataset_base_test_dir)\n",
    "print('dataset_labels_test_file:',dataset_labels_test_file)\n",
    "print('            dataset_name:',dataset_name)\n",
    "print('              model_type:',model_type)\n",
    "print('                  EPOCAS:',EPOCAS)\n",
    "print('              BATCH_SIZE:',BATCH_SIZE)\n",
    "print('             fine_tuning:',fine_tuning)\n",
    "print('         output_base_dir:',output_base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1dee5-778a-4fd9-80de-90620bb33128",
   "metadata": {},
   "source": [
    "# Set seed of random variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ddef12f-6604-4c71-9473-15f328e954dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "tf.keras.utils.set_random_seed(seed_number);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a59004-739e-4760-bd91-ee3808207e3e",
   "metadata": {},
   "source": [
    "# Loading data of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1abe0e9b-ee46-40d8-97c3-12a1efc0cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   filename     label\n",
      "0     patient/filename1.png  Negative\n",
      "1     patient/filename2.png  Negative\n",
      "2     patient/filename3.png      Pain\n",
      "3     patient/filename4.png  Negative\n",
      "4     patient/filename5.png      Pain\n",
      "..                      ...       ...\n",
      "626  people/filename349.png    Neutro\n",
      "627  people/filename350.png    Neutro\n",
      "628  people/filename351.png    Neutro\n",
      "629  people/filename352.png    Neutro\n",
      "630  people/filename354.png  Positive\n",
      "\n",
      "[631 rows x 2 columns]\n",
      "                    filename     label\n",
      "0    patient/filename302.png  Positive\n",
      "1    patient/filename303.png  Positive\n",
      "2    patient/filename304.png  Positive\n",
      "3    patient/filename305.png  Positive\n",
      "4    patient/filename306.png  Positive\n",
      "..                       ...       ...\n",
      "268   people/filename522.png  Positive\n",
      "269   people/filename525.png    Neutro\n",
      "270   people/filename526.png  Positive\n",
      "271   people/filename527.png    Neutro\n",
      "272   people/filename528.png    Neutro\n",
      "\n",
      "[273 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load filenames and labels\n",
    "train_val_data = pd.read_csv(os.path.join(dataset_base_dir,dataset_labels_file));\n",
    "print(train_val_data)\n",
    "\n",
    "# Setting labels\n",
    "Y = train_val_data[['label']];\n",
    "L=np.shape(Y)[0];\n",
    "\n",
    "# Load test filenames and labels\n",
    "test_data = pd.read_csv(os.path.join(dataset_base_test_dir,dataset_labels_test_file));\n",
    "print(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da712f-5937-4965-9623-82c4ee139297",
   "metadata": {},
   "source": [
    "# Setting the cross-validation split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcab2262-3467-4ee3-86a8-9eda4f5ff726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, validation_data = train_test_split(train_val_data, test_size=0.2,shuffle=True, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67beeb38-1ad1-455d-8a71-5900a1e88163",
   "metadata": {},
   "source": [
    "# Data augmentation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2e3e68f-50e7-4f8c-9cd6-ae3261e8f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "idg    = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range = 10,\n",
    "                            width_shift_range= 0.07,\n",
    "                            height_shift_range= 0.07,\n",
    "                            horizontal_flip=True,\n",
    "                            shear_range=1.25,\n",
    "                            zoom_range = [0.75, 1.25] \n",
    "                            )\n",
    "\n",
    "idg_val= ImageDataGenerator(rescale=1./255 )\n",
    "\n",
    "idg_test= ImageDataGenerator(rescale=1./255 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5189cf-b447-4b0a-b9f3-56f304d6fdde",
   "metadata": {},
   "source": [
    "# Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a786de7-43ac-4597-92eb-d9eee66f81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tuning:\n",
    "    output_dir = os.path.join(output_base_dir,dataset_name,'training_validation_holdout_fine_tuning',model_type);\n",
    "else:\n",
    "    output_dir = os.path.join(output_base_dir,dataset_name,'training_validation_holdout',model_type);\n",
    "\n",
    "os.makedirs(output_base_dir,exist_ok = True);\n",
    "\n",
    "os.makedirs(output_dir,exist_ok = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf04e51-7a7b-4116-8e1e-04e5f358c5dc",
   "metadata": {},
   "source": [
    "# Create new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d629ba9-d621-4905-a88f-a0730d6c1802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading architecture mobilenet_v3\n",
      "\n",
      "        url: https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/feature_vector/5\n",
      "target_size: (224, 224)\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1024)              1529968   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 4100      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,534,068\n",
      "Trainable params: 4,100\n",
      "Non-trainable params: 1,529,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import BodyEmotion4Lib.lib_model as mpp\n",
    "\n",
    "model, target_size = mpp.create_model(model_type=model_type,load_weights=False);\n",
    "model.summary()\n",
    "\n",
    "mpp.save_model_parameters(model, os.path.join(output_dir,'parameters_stats.m'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59917a-4069-439f-9108-e5b139498b01",
   "metadata": {},
   "source": [
    "# Defining directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac8f2152-96da-447d-b437-84f11e12937f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 504 validated image filenames belonging to 4 classes.\n",
      "Found 127 validated image filenames belonging to 4 classes.\n",
      "Found 273 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data_generator = idg.flow_from_dataframe(training_data, \n",
    "                                               directory = dataset_base_dir,\n",
    "                                               target_size=target_size,\n",
    "                                               x_col = \"filename\", \n",
    "                                               y_col = \"label\",\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               shuffle = True);\n",
    "\n",
    "valid_data_generator  = idg_val.flow_from_dataframe(validation_data, \n",
    "                                                    directory = dataset_base_dir,\n",
    "                                                    target_size=target_size,\n",
    "                                                    x_col = \"filename\", \n",
    "                                                    y_col = \"label\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    shuffle = True);\n",
    "\n",
    "\n",
    "\n",
    "test_data_generator  = idg_test.flow_from_dataframe(test_data, \n",
    "                                                    directory = dataset_base_test_dir,\n",
    "                                                    target_size=target_size,\n",
    "                                                    x_col = \"filename\", \n",
    "                                                    y_col = \"label\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    shuffle = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1be572-b9c7-422c-9518-53735f9425c7",
   "metadata": {},
   "source": [
    "# Train and validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13cd68b8-e1aa-4ef4-af04-e05781f309ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3147 - categorical_accuracy: 0.3810\n",
      "Epoch 1: val_loss improved from inf to 1.16100, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 16s 850ms/step - loss: 1.3147 - categorical_accuracy: 0.3810 - val_loss: 1.1610 - val_categorical_accuracy: 0.4882\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1580 - categorical_accuracy: 0.4742\n",
      "Epoch 2: val_loss improved from 1.16100 to 1.06395, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 651ms/step - loss: 1.1580 - categorical_accuracy: 0.4742 - val_loss: 1.0639 - val_categorical_accuracy: 0.5276\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0456 - categorical_accuracy: 0.5198\n",
      "Epoch 3: val_loss improved from 1.06395 to 1.01001, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 11s 662ms/step - loss: 1.0456 - categorical_accuracy: 0.5198 - val_loss: 1.0100 - val_categorical_accuracy: 0.5669\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9858 - categorical_accuracy: 0.5615\n",
      "Epoch 4: val_loss improved from 1.01001 to 0.97112, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 11s 661ms/step - loss: 0.9858 - categorical_accuracy: 0.5615 - val_loss: 0.9711 - val_categorical_accuracy: 0.5984\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9369 - categorical_accuracy: 0.5853\n",
      "Epoch 5: val_loss improved from 0.97112 to 0.94727, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 11s 659ms/step - loss: 0.9369 - categorical_accuracy: 0.5853 - val_loss: 0.9473 - val_categorical_accuracy: 0.6299\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8839 - categorical_accuracy: 0.6052\n",
      "Epoch 6: val_loss improved from 0.94727 to 0.94288, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 640ms/step - loss: 0.8839 - categorical_accuracy: 0.6052 - val_loss: 0.9429 - val_categorical_accuracy: 0.6457\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8501 - categorical_accuracy: 0.6567\n",
      "Epoch 7: val_loss improved from 0.94288 to 0.92642, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 639ms/step - loss: 0.8501 - categorical_accuracy: 0.6567 - val_loss: 0.9264 - val_categorical_accuracy: 0.6535\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8104 - categorical_accuracy: 0.6627\n",
      "Epoch 8: val_loss improved from 0.92642 to 0.92535, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 644ms/step - loss: 0.8104 - categorical_accuracy: 0.6627 - val_loss: 0.9253 - val_categorical_accuracy: 0.6457\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7907 - categorical_accuracy: 0.6667\n",
      "Epoch 9: val_loss improved from 0.92535 to 0.91393, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 644ms/step - loss: 0.7907 - categorical_accuracy: 0.6667 - val_loss: 0.9139 - val_categorical_accuracy: 0.6457\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7583 - categorical_accuracy: 0.6944\n",
      "Epoch 10: val_loss improved from 0.91393 to 0.90850, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 638ms/step - loss: 0.7583 - categorical_accuracy: 0.6944 - val_loss: 0.9085 - val_categorical_accuracy: 0.6535\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7448 - categorical_accuracy: 0.6944\n",
      "Epoch 11: val_loss improved from 0.90850 to 0.90170, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 640ms/step - loss: 0.7448 - categorical_accuracy: 0.6944 - val_loss: 0.9017 - val_categorical_accuracy: 0.6614\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7406 - categorical_accuracy: 0.7083\n",
      "Epoch 12: val_loss did not improve from 0.90170\n",
      "16/16 [==============================] - 11s 708ms/step - loss: 0.7406 - categorical_accuracy: 0.7083 - val_loss: 0.9068 - val_categorical_accuracy: 0.6457\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7022 - categorical_accuracy: 0.6964\n",
      "Epoch 13: val_loss did not improve from 0.90170\n",
      "16/16 [==============================] - 12s 726ms/step - loss: 0.7022 - categorical_accuracy: 0.6964 - val_loss: 0.9071 - val_categorical_accuracy: 0.6457\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6894 - categorical_accuracy: 0.7401\n",
      "Epoch 14: val_loss improved from 0.90170 to 0.89717, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 12s 743ms/step - loss: 0.6894 - categorical_accuracy: 0.7401 - val_loss: 0.8972 - val_categorical_accuracy: 0.6457\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6711 - categorical_accuracy: 0.7381\n",
      "Epoch 15: val_loss did not improve from 0.89717\n",
      "16/16 [==============================] - 14s 891ms/step - loss: 0.6711 - categorical_accuracy: 0.7381 - val_loss: 0.9020 - val_categorical_accuracy: 0.6220\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6439 - categorical_accuracy: 0.7758\n",
      "Epoch 16: val_loss improved from 0.89717 to 0.88793, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 637ms/step - loss: 0.6439 - categorical_accuracy: 0.7758 - val_loss: 0.8879 - val_categorical_accuracy: 0.6535\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6216 - categorical_accuracy: 0.7778\n",
      "Epoch 17: val_loss improved from 0.88793 to 0.88633, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 640ms/step - loss: 0.6216 - categorical_accuracy: 0.7778 - val_loss: 0.8863 - val_categorical_accuracy: 0.6614\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6120 - categorical_accuracy: 0.7956\n",
      "Epoch 18: val_loss did not improve from 0.88633\n",
      "16/16 [==============================] - 10s 631ms/step - loss: 0.6120 - categorical_accuracy: 0.7956 - val_loss: 0.8912 - val_categorical_accuracy: 0.6535\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5927 - categorical_accuracy: 0.7817\n",
      "Epoch 19: val_loss improved from 0.88633 to 0.88560, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 11s 674ms/step - loss: 0.5927 - categorical_accuracy: 0.7817 - val_loss: 0.8856 - val_categorical_accuracy: 0.6693\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6004 - categorical_accuracy: 0.7778\n",
      "Epoch 20: val_loss did not improve from 0.88560\n",
      "16/16 [==============================] - 10s 633ms/step - loss: 0.6004 - categorical_accuracy: 0.7778 - val_loss: 0.8951 - val_categorical_accuracy: 0.6457\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5990 - categorical_accuracy: 0.7917\n",
      "Epoch 21: val_loss did not improve from 0.88560\n",
      "16/16 [==============================] - 10s 635ms/step - loss: 0.5990 - categorical_accuracy: 0.7917 - val_loss: 0.8886 - val_categorical_accuracy: 0.6614\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5631 - categorical_accuracy: 0.8036\n",
      "Epoch 22: val_loss improved from 0.88560 to 0.88510, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 638ms/step - loss: 0.5631 - categorical_accuracy: 0.8036 - val_loss: 0.8851 - val_categorical_accuracy: 0.6378\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5798 - categorical_accuracy: 0.7758\n",
      "Epoch 23: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 638ms/step - loss: 0.5798 - categorical_accuracy: 0.7758 - val_loss: 0.8910 - val_categorical_accuracy: 0.6457\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5438 - categorical_accuracy: 0.8274\n",
      "Epoch 24: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 11s 651ms/step - loss: 0.5438 - categorical_accuracy: 0.8274 - val_loss: 0.9021 - val_categorical_accuracy: 0.6457\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5406 - categorical_accuracy: 0.8036\n",
      "Epoch 25: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 637ms/step - loss: 0.5406 - categorical_accuracy: 0.8036 - val_loss: 0.8950 - val_categorical_accuracy: 0.6535\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5381 - categorical_accuracy: 0.7976\n",
      "Epoch 26: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 629ms/step - loss: 0.5381 - categorical_accuracy: 0.7976 - val_loss: 0.8986 - val_categorical_accuracy: 0.6614\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5599 - categorical_accuracy: 0.7857\n",
      "Epoch 27: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 636ms/step - loss: 0.5599 - categorical_accuracy: 0.7857 - val_loss: 0.8960 - val_categorical_accuracy: 0.6535\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5411 - categorical_accuracy: 0.7976\n",
      "Epoch 28: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 635ms/step - loss: 0.5411 - categorical_accuracy: 0.7976 - val_loss: 0.8913 - val_categorical_accuracy: 0.6614\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5346 - categorical_accuracy: 0.8075\n",
      "Epoch 29: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 634ms/step - loss: 0.5346 - categorical_accuracy: 0.8075 - val_loss: 0.9034 - val_categorical_accuracy: 0.6378\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5238 - categorical_accuracy: 0.8175\n",
      "Epoch 30: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 638ms/step - loss: 0.5238 - categorical_accuracy: 0.8175 - val_loss: 0.8938 - val_categorical_accuracy: 0.6378\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4898 - categorical_accuracy: 0.8333\n",
      "Epoch 31: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 632ms/step - loss: 0.4898 - categorical_accuracy: 0.8333 - val_loss: 0.8890 - val_categorical_accuracy: 0.6457\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4698 - categorical_accuracy: 0.8413\n",
      "Epoch 32: val_loss improved from 0.88510 to 0.88321, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 629ms/step - loss: 0.4698 - categorical_accuracy: 0.8413 - val_loss: 0.8832 - val_categorical_accuracy: 0.6535\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4924 - categorical_accuracy: 0.8333\n",
      "Epoch 33: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 635ms/step - loss: 0.4924 - categorical_accuracy: 0.8333 - val_loss: 0.8862 - val_categorical_accuracy: 0.6535\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4930 - categorical_accuracy: 0.8254\n",
      "Epoch 34: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 633ms/step - loss: 0.4930 - categorical_accuracy: 0.8254 - val_loss: 0.8935 - val_categorical_accuracy: 0.6299\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4612 - categorical_accuracy: 0.8472\n",
      "Epoch 35: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 627ms/step - loss: 0.4612 - categorical_accuracy: 0.8472 - val_loss: 0.8937 - val_categorical_accuracy: 0.6614\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4718 - categorical_accuracy: 0.8452\n",
      "Epoch 36: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 632ms/step - loss: 0.4718 - categorical_accuracy: 0.8452 - val_loss: 0.8907 - val_categorical_accuracy: 0.6220\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4606 - categorical_accuracy: 0.8393\n",
      "Epoch 37: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 635ms/step - loss: 0.4606 - categorical_accuracy: 0.8393 - val_loss: 0.8909 - val_categorical_accuracy: 0.6299\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4631 - categorical_accuracy: 0.8532\n",
      "Epoch 38: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 638ms/step - loss: 0.4631 - categorical_accuracy: 0.8532 - val_loss: 0.8901 - val_categorical_accuracy: 0.6220\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4436 - categorical_accuracy: 0.8750\n",
      "Epoch 39: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 631ms/step - loss: 0.4436 - categorical_accuracy: 0.8750 - val_loss: 0.8938 - val_categorical_accuracy: 0.6299\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4321 - categorical_accuracy: 0.8730\n",
      "Epoch 40: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 633ms/step - loss: 0.4321 - categorical_accuracy: 0.8730 - val_loss: 0.8858 - val_categorical_accuracy: 0.6220\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4535 - categorical_accuracy: 0.8472\n",
      "Epoch 41: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 633ms/step - loss: 0.4535 - categorical_accuracy: 0.8472 - val_loss: 0.8929 - val_categorical_accuracy: 0.6299\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4384 - categorical_accuracy: 0.8591\n",
      "Epoch 42: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 656ms/step - loss: 0.4384 - categorical_accuracy: 0.8591 - val_loss: 0.8878 - val_categorical_accuracy: 0.6299\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4361 - categorical_accuracy: 0.8512\n",
      "Epoch 43: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 640ms/step - loss: 0.4361 - categorical_accuracy: 0.8512 - val_loss: 0.8945 - val_categorical_accuracy: 0.6220\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4170 - categorical_accuracy: 0.8552\n",
      "Epoch 44: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 646ms/step - loss: 0.4170 - categorical_accuracy: 0.8552 - val_loss: 0.9023 - val_categorical_accuracy: 0.6220\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4265 - categorical_accuracy: 0.8512\n",
      "Epoch 45: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 639ms/step - loss: 0.4265 - categorical_accuracy: 0.8512 - val_loss: 0.9028 - val_categorical_accuracy: 0.6220\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4392 - categorical_accuracy: 0.8591\n",
      "Epoch 46: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 636ms/step - loss: 0.4392 - categorical_accuracy: 0.8591 - val_loss: 0.9074 - val_categorical_accuracy: 0.6535\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4110 - categorical_accuracy: 0.8829\n",
      "Epoch 47: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 633ms/step - loss: 0.4110 - categorical_accuracy: 0.8829 - val_loss: 0.9039 - val_categorical_accuracy: 0.6378\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3988 - categorical_accuracy: 0.8909\n",
      "Epoch 48: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 640ms/step - loss: 0.3988 - categorical_accuracy: 0.8909 - val_loss: 0.9013 - val_categorical_accuracy: 0.6614\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4190 - categorical_accuracy: 0.8651\n",
      "Epoch 49: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 634ms/step - loss: 0.4190 - categorical_accuracy: 0.8651 - val_loss: 0.9007 - val_categorical_accuracy: 0.6850\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3977 - categorical_accuracy: 0.8889\n",
      "Epoch 50: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 631ms/step - loss: 0.3977 - categorical_accuracy: 0.8889 - val_loss: 0.8991 - val_categorical_accuracy: 0.6693\n",
      "max_val_acc 0.6850393414497375\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "STEPS_BY_EPOCHS=len(train_data_generator);\n",
    "\n",
    "# COMPILE NEW MODEL\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "# CREATE CALLBACKS\n",
    "best_model_file=os.path.join(output_dir,'model.h5');\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=best_model_file, \n",
    "                                                save_weights_only=True,\n",
    "                                                monitor='val_loss', \n",
    "                                                save_best_only=True, \n",
    "                                                verbose=1);\n",
    "\n",
    "log_dir = os.path.join(output_dir,\"logs\",\"fit\",'coarse_tunning-'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"));\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# There can be other callbacks, but just showing one because it involves the model name\n",
    "# This saves the best model\n",
    "# FIT THE MODEL\n",
    "history = model.fit(train_data_generator,\n",
    "                    steps_per_epoch=STEPS_BY_EPOCHS,\n",
    "                    epochs=EPOCAS,\n",
    "                    validation_data=valid_data_generator,\n",
    "                    callbacks=[checkpoint,tensorboard_callback],\n",
    "                    verbose=1\n",
    "                   );\n",
    "\n",
    "\n",
    "mpp.save_model_history(history,\n",
    "                       os.path.join(output_dir,\"historical.csv\"),\n",
    "                       show=False,\n",
    "                       labels=['categorical_accuracy','loss']);\n",
    "\n",
    "if fine_tuning:\n",
    "    tf.keras.backend.clear_session();\n",
    "    #import torch\n",
    "    #torch.cuda.empty_cache();\n",
    "    del model\n",
    "    del history\n",
    "    \n",
    "    model, target_size = mpp.create_model(model_type=model_type,load_weights=False,file_of_weight=best_model_file);\n",
    "    #model.load_weights(best_model_file);\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True;\n",
    "\n",
    "    #necessary for these changes to take effect\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])\n",
    "    \n",
    "    model.summary();\n",
    "    \n",
    "    log_dir = os.path.join(output_dir,\"logs\",\"fit\",'fine_tunning-'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"));\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    history = model.fit(train_data_generator,\n",
    "                        steps_per_epoch=STEPS_BY_EPOCHS,\n",
    "                        epochs=EPOCAS,\n",
    "                        validation_data=valid_data_generator,\n",
    "                        callbacks=[checkpoint,tensorboard_callback],\n",
    "                        verbose=1\n",
    "                    );\n",
    "\n",
    "\n",
    "    mpp.save_model_history(history,\n",
    "                        os.path.join(output_dir,\"historical-fine_tuning.csv\"),\n",
    "                        show=False,\n",
    "                        labels=['categorical_accuracy','loss']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083be078-c76e-423a-a538-6e5c6c9cda8c",
   "metadata": {},
   "source": [
    "# Evaluate best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d4f6536-46f0-4c89-b98f-7cb5a4075cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 9s 565ms/step - loss: 0.4786 - categorical_accuracy: 0.8373\n",
      "training {'loss': 0.4786042273044586, 'categorical_accuracy': 0.8373016119003296} \n",
      "\n",
      "\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 0.8832 - categorical_accuracy: 0.6535\n",
      "validation {'loss': 0.8832107782363892, 'categorical_accuracy': 0.6535432934761047} \n",
      "\n",
      "\n",
      "9/9 [==============================] - 7s 774ms/step - loss: 1.0629 - categorical_accuracy: 0.5568\n",
      "testing {'loss': 1.062915563583374, 'categorical_accuracy': 0.5567765831947327} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LOAD BEST MODEL to evaluate the performance of the model\n",
    "model.load_weights(best_model_file);\n",
    "data_results=dict();\n",
    "\n",
    "# Evaluate training\n",
    "results = model.evaluate(train_data_generator)\n",
    "results = dict(zip(model.metrics_names,results))\n",
    "print('training',results,\"\\n\\n\");\n",
    "for key,value in results.items():\n",
    "    data_results['train_'+key]=value;\n",
    "\n",
    "# Evaluate validation\n",
    "results = model.evaluate(valid_data_generator)\n",
    "results = dict(zip(model.metrics_names,results))\n",
    "print('validation',results,\"\\n\\n\");\n",
    "for key,value in results.items():\n",
    "    data_results['val_'+key]=value;\n",
    "\n",
    "# Evaluate testing\n",
    "results = model.evaluate(test_data_generator)\n",
    "results = dict(zip(model.metrics_names,results))\n",
    "print('testing',results,\"\\n\\n\");\n",
    "for key,value in results.items():\n",
    "    data_results['test_'+key]=value;\n",
    "\n",
    "data_results['number_of_parameters']=mpp.get_model_parameters(model);\n",
    "\n",
    "# final all json\n",
    "with open(os.path.join(output_dir,\"training_data_results.json\"), 'w') as f:\n",
    "    json.dump(data_results, f,indent=4);\n",
    "\n",
    "# final test txt\n",
    "with open(os.path.join(output_dir,\"results_testing.txt\"), 'w') as f: \n",
    "    for key, value in results.items(): \n",
    "        f.write('%s=%s;\\n' % (key, value));\n",
    "\n",
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84facfa9-b65a-4fc8-85c7-025fd02f1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#POSTNAME=str(int(results['accuracy']*100000));\n",
    "#tmp_name='modelo_'+model_type+'_acc'+POSTNAME+'.h5';\n",
    "\n",
    "tmp_name='model_'+model_type+'.h5';\n",
    "\n",
    "os.rename(best_model_file,os.path.join(output_dir,tmp_name));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
